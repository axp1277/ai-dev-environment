[ Skip to content ](https://langchain-ai.github.io/langgraph/concepts/persistence/#persistence)
**We are growing and hiring for multiple roles for LangChain, LangGraph and LangSmith.[ Join our team!](https://www.langchain.com/careers)**
[ ![logo](https://langchain-ai.github.io/langgraph/static/wordmark_dark.svg) ![logo](https://langchain-ai.github.io/langgraph/static/wordmark_light.svg) ](https://langchain-ai.github.io/langgraph/ "LangGraph")
LangGraph 
Overview 
[ ](https://langchain-ai.github.io/langgraph/concepts/persistence/?q= "Share")
Initializing search 
[ GitHub  ](https://github.com/langchain-ai/langgraph "Go to repository")
  * [ Guides ](https://langchain-ai.github.io/langgraph/)
  * [ Reference ](https://langchain-ai.github.io/langgraph/reference/)
  * [ Examples ](https://langchain-ai.github.io/langgraph/tutorials/rag/langgraph_agentic_rag/)
  * [ Resources ](https://langchain-ai.github.io/langgraph/concepts/faq/)


[ ![logo](https://langchain-ai.github.io/langgraph/static/wordmark_dark.svg) ![logo](https://langchain-ai.github.io/langgraph/static/wordmark_light.svg) ](https://langchain-ai.github.io/langgraph/ "LangGraph") LangGraph 
[ GitHub  ](https://github.com/langchain-ai/langgraph "Go to repository")
  * [ Guides  ](https://langchain-ai.github.io/langgraph/)
    * Get started 
      * [ Quickstart  ](https://langchain-ai.github.io/langgraph/agents/agents/)
      * [ LangGraph basics  ](https://langchain-ai.github.io/langgraph/concepts/why-langgraph/)
      * [ Deployment  ](https://langchain-ai.github.io/langgraph/tutorials/deployment/)
    * Prebuilt agents 
      * [ Overview  ](https://langchain-ai.github.io/langgraph/agents/overview/)
      * [ Running agents  ](https://langchain-ai.github.io/langgraph/agents/run_agents/)
      * [ Streaming  ](https://langchain-ai.github.io/langgraph/agents/streaming/)
      * [ Models  ](https://langchain-ai.github.io/langgraph/agents/models/)
      * [ Tools  ](https://langchain-ai.github.io/langgraph/agents/tools/)
      * [ MCP Integration  ](https://langchain-ai.github.io/langgraph/agents/mcp/)
      * [ Context  ](https://langchain-ai.github.io/langgraph/agents/context/)
      * [ Memory  ](https://langchain-ai.github.io/langgraph/agents/memory/)
      * [ Human-in-the-loop  ](https://langchain-ai.github.io/langgraph/agents/human-in-the-loop/)
      * [ Multi-agent  ](https://langchain-ai.github.io/langgraph/agents/multi-agent/)
      * [ Evals  ](https://langchain-ai.github.io/langgraph/agents/evals/)
      * [ Deployment  ](https://langchain-ai.github.io/langgraph/agents/deployment/)
      * [ UI  ](https://langchain-ai.github.io/langgraph/agents/ui/)
    * LangGraph framework 
      * [ Agent architectures  ](https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/)
      * [ Graphs  ](https://langchain-ai.github.io/langgraph/concepts/low_level/)
      * [ Streaming  ](https://langchain-ai.github.io/langgraph/concepts/streaming/)
      * Persistence 
        * Overview  [ Overview  ](https://langchain-ai.github.io/langgraph/concepts/persistence/)
          * [ Threads  ](https://langchain-ai.github.io/langgraph/concepts/persistence/#threads)
          * [ Checkpoints  ](https://langchain-ai.github.io/langgraph/concepts/persistence/#checkpoints)
            * [ Get state  ](https://langchain-ai.github.io/langgraph/concepts/persistence/#get-state)
            * [ Get state history  ](https://langchain-ai.github.io/langgraph/concepts/persistence/#get-state-history)
            * [ Replay  ](https://langchain-ai.github.io/langgraph/concepts/persistence/#replay)
            * [ Update state  ](https://langchain-ai.github.io/langgraph/concepts/persistence/#update-state)
              * [ config  ](https://langchain-ai.github.io/langgraph/concepts/persistence/#config)
              * [ values  ](https://langchain-ai.github.io/langgraph/concepts/persistence/#values)
              * [ as_node  ](https://langchain-ai.github.io/langgraph/concepts/persistence/#as_node)
          * [ Memory Store  ](https://langchain-ai.github.io/langgraph/concepts/persistence/#memory-store)
            * [ Basic Usage  ](https://langchain-ai.github.io/langgraph/concepts/persistence/#basic-usage)
            * [ Semantic Search  ](https://langchain-ai.github.io/langgraph/concepts/persistence/#semantic-search)
            * [ Using in LangGraph  ](https://langchain-ai.github.io/langgraph/concepts/persistence/#using-in-langgraph)
          * [ Checkpointer libraries  ](https://langchain-ai.github.io/langgraph/concepts/persistence/#checkpointer-libraries)
            * [ Checkpointer interface  ](https://langchain-ai.github.io/langgraph/concepts/persistence/#checkpointer-interface)
            * [ Serializer  ](https://langchain-ai.github.io/langgraph/concepts/persistence/#serializer)
          * [ Capabilities  ](https://langchain-ai.github.io/langgraph/concepts/persistence/#capabilities)
            * [ Human-in-the-loop  ](https://langchain-ai.github.io/langgraph/concepts/persistence/#human-in-the-loop)
            * [ Memory  ](https://langchain-ai.github.io/langgraph/concepts/persistence/#memory)
            * [ Time Travel  ](https://langchain-ai.github.io/langgraph/concepts/persistence/#time-travel)
            * [ Fault-tolerance  ](https://langchain-ai.github.io/langgraph/concepts/persistence/#fault-tolerance)
              * [ Pending writes  ](https://langchain-ai.github.io/langgraph/concepts/persistence/#pending-writes)
        * [ Durable Execution  ](https://langchain-ai.github.io/langgraph/concepts/durable_execution/)
        * [ Add persistence  ](https://langchain-ai.github.io/langgraph/how-tos/persistence/)
      * [ Memory  ](https://langchain-ai.github.io/langgraph/concepts/memory/)
      * [ Human-in-the-loop  ](https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/)
      * [ Breakpoints  ](https://langchain-ai.github.io/langgraph/concepts/breakpoints/)
      * [ Time travel  ](https://langchain-ai.github.io/langgraph/concepts/time-travel/)
      * [ Tools  ](https://langchain-ai.github.io/langgraph/concepts/tools/)
      * [ Subgraphs  ](https://langchain-ai.github.io/langgraph/concepts/subgraphs/)
      * [ Multi-agent  ](https://langchain-ai.github.io/langgraph/concepts/multi_agent/)
      * [ Functional API  ](https://langchain-ai.github.io/langgraph/concepts/functional_api/)
      * [ LangGraph's Runtime (Pregel)  ](https://langchain-ai.github.io/langgraph/concepts/pregel/)
      * [ Other  ](https://langchain-ai.github.io/langgraph/how-tos/async/)
    * LangGraph Platform 
      * [ Overview  ](https://langchain-ai.github.io/langgraph/concepts/langgraph_platform/)
      * [ Get started  ](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/)
      * [ Components  ](https://langchain-ai.github.io/langgraph/concepts/langgraph_components/)
      * [ Data management  ](https://langchain-ai.github.io/langgraph/cloud/deployment/semantic_search/)
      * [ Authentication & access control  ](https://langchain-ai.github.io/langgraph/concepts/auth/)
      * [ Assistants  ](https://langchain-ai.github.io/langgraph/concepts/assistants/)
      * [ Threads  ](https://langchain-ai.github.io/langgraph/cloud/concepts/threads/)
      * [ Runs  ](https://langchain-ai.github.io/langgraph/cloud/concepts/runs/)
      * [ Streaming  ](https://langchain-ai.github.io/langgraph/cloud/concepts/streaming/)
      * [ Human-in-the-loop  ](https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_breakpoint/)
      * [ MCP  ](https://langchain-ai.github.io/langgraph/concepts/server-mcp/)
      * [ Double-texting  ](https://langchain-ai.github.io/langgraph/concepts/double_texting/)
      * [ Webhooks  ](https://langchain-ai.github.io/langgraph/cloud/concepts/webhooks/)
      * [ Cron Jobs  ](https://langchain-ai.github.io/langgraph/cloud/concepts/cron_jobs/)
      * [ Server Customization  ](https://langchain-ai.github.io/langgraph/how-tos/http/custom_lifespan/)
      * [ Deployment  ](https://langchain-ai.github.io/langgraph/concepts/deployment_options/)
  * [ Reference  ](https://langchain-ai.github.io/langgraph/reference/)
  * [ Examples  ](https://langchain-ai.github.io/langgraph/tutorials/rag/langgraph_agentic_rag/)
  * [ Resources  ](https://langchain-ai.github.io/langgraph/concepts/faq/)


  * [ Threads  ](https://langchain-ai.github.io/langgraph/concepts/persistence/#threads)
  * [ Checkpoints  ](https://langchain-ai.github.io/langgraph/concepts/persistence/#checkpoints)
    * [ Get state  ](https://langchain-ai.github.io/langgraph/concepts/persistence/#get-state)
    * [ Get state history  ](https://langchain-ai.github.io/langgraph/concepts/persistence/#get-state-history)
    * [ Replay  ](https://langchain-ai.github.io/langgraph/concepts/persistence/#replay)
    * [ Update state  ](https://langchain-ai.github.io/langgraph/concepts/persistence/#update-state)
      * [ config  ](https://langchain-ai.github.io/langgraph/concepts/persistence/#config)
      * [ values  ](https://langchain-ai.github.io/langgraph/concepts/persistence/#values)
      * [ as_node  ](https://langchain-ai.github.io/langgraph/concepts/persistence/#as_node)
  * [ Memory Store  ](https://langchain-ai.github.io/langgraph/concepts/persistence/#memory-store)
    * [ Basic Usage  ](https://langchain-ai.github.io/langgraph/concepts/persistence/#basic-usage)
    * [ Semantic Search  ](https://langchain-ai.github.io/langgraph/concepts/persistence/#semantic-search)
    * [ Using in LangGraph  ](https://langchain-ai.github.io/langgraph/concepts/persistence/#using-in-langgraph)
  * [ Checkpointer libraries  ](https://langchain-ai.github.io/langgraph/concepts/persistence/#checkpointer-libraries)
    * [ Checkpointer interface  ](https://langchain-ai.github.io/langgraph/concepts/persistence/#checkpointer-interface)
    * [ Serializer  ](https://langchain-ai.github.io/langgraph/concepts/persistence/#serializer)
  * [ Capabilities  ](https://langchain-ai.github.io/langgraph/concepts/persistence/#capabilities)
    * [ Human-in-the-loop  ](https://langchain-ai.github.io/langgraph/concepts/persistence/#human-in-the-loop)
    * [ Memory  ](https://langchain-ai.github.io/langgraph/concepts/persistence/#memory)
    * [ Time Travel  ](https://langchain-ai.github.io/langgraph/concepts/persistence/#time-travel)
    * [ Fault-tolerance  ](https://langchain-ai.github.io/langgraph/concepts/persistence/#fault-tolerance)
      * [ Pending writes  ](https://langchain-ai.github.io/langgraph/concepts/persistence/#pending-writes)


  1. [ Guides  ](https://langchain-ai.github.io/langgraph/)
  2. [ LangGraph framework  ](https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/)
  3. [ Persistence  ](https://langchain-ai.github.io/langgraph/concepts/persistence/)

[ ](https://github.com/langchain-ai/langgraph/edit/main/docs/docs/concepts/persistence.md "Edit this page")
# Persistence[¶](https://langchain-ai.github.io/langgraph/concepts/persistence/#persistence "Permanent link")
LangGraph has a built-in persistence layer, implemented through checkpointers. When you compile graph with a checkpointer, the checkpointer saves a `checkpoint` of the graph state at every super-step. Those checkpoints are saved to a `thread`, which can be accessed after graph execution. Because `threads` allow access to graph's state after execution, several powerful capabilities including human-in-the-loop, memory, time travel, and fault-tolerance are all possible. See [this how-to guide](https://langchain-ai.github.io/langgraph/how-tos/persistence/) for an end-to-end example on how to add and use checkpointers with your graph. Below, we'll discuss each of these concepts in more detail. 
![Checkpoints](https://langchain-ai.github.io/langgraph/concepts/img/persistence/checkpoints.jpg)
LangGraph API handles checkpointing automatically
When using the LangGraph API, you don't need to implement or configure checkpointers manually. The API handles all persistence infrastructure for you behind the scenes.
## Threads[¶](https://langchain-ai.github.io/langgraph/concepts/persistence/#threads "Permanent link")
A thread is a unique ID or [thread identifier](https://langchain-ai.github.io/langgraph/concepts/persistence/#threads) assigned to each checkpoint saved by a checkpointer. When invoking graph with a checkpointer, you **must** specify a `thread_id` as part of the `configurable` portion of the config:
```
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-0-1){"configurable": {"thread_id": "1"}}

```

## Checkpoints[¶](https://langchain-ai.github.io/langgraph/concepts/persistence/#checkpoints "Permanent link")
Checkpoint is a snapshot of the graph state saved at each super-step and is represented by `StateSnapshot` object with the following key properties:
  * `config`: Config associated with this checkpoint. 
  * `metadata`: Metadata associated with this checkpoint.
  * `values`: Values of the state channels at this point in time.
  * `next` A tuple of the node names to execute next in the graph.
  * `tasks`: A tuple of `PregelTask` objects that contain information about next tasks to be executed. If the step was previously attempted, it will include error information. If a graph was interrupted [dynamically](https://langchain-ai.github.io/langgraph/concepts/how-tos/human_in_the_loop/dynamic_breakpoints.ipynb) from within a node, tasks will contain additional data associated with interrupts.


Let's see what checkpoints are saved when a simple graph is invoked as follows:
_API Reference:[StateGraph](https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.state.StateGraph) | [START](https://langchain-ai.github.io/langgraph/reference/constants/#langgraph.constants.START) | [END](https://langchain-ai.github.io/langgraph/reference/constants/#langgraph.constants.END) | [InMemorySaver](https://langchain-ai.github.io/langgraph/reference/checkpoints/#langgraph.checkpoint.memory.InMemorySaver)_
```
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-1-1)fromlanggraph.graphimport StateGraph, START, END
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-1-2)fromlanggraph.checkpoint.memoryimport InMemorySaver
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-1-3)fromtypingimport Annotated
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-1-4)fromtyping_extensionsimport TypedDict
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-1-5)fromoperatorimport add
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-1-6)
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-1-7)classState(TypedDict):
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-1-8)    foo: str
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-1-9)    bar: Annotated[list[str], add]
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-1-10)
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-1-11)defnode_a(state: State):
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-1-12)    return {"foo": "a", "bar": ["a"]}
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-1-13)
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-1-14)defnode_b(state: State):
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-1-15)    return {"foo": "b", "bar": ["b"]}
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-1-16)
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-1-17)
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-1-18)workflow = StateGraph(State)
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-1-19)workflow.add_node(node_a)
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-1-20)workflow.add_node(node_b)
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-1-21)workflow.add_edge(START, "node_a")
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-1-22)workflow.add_edge("node_a", "node_b")
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-1-23)workflow.add_edge("node_b", END)
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-1-24)
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-1-25)checkpointer = InMemorySaver()
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-1-26)graph = workflow.compile(checkpointer=checkpointer)
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-1-27)
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-1-28)config = {"configurable": {"thread_id": "1"}}
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-1-29)graph.invoke({"foo": ""}, config)

```

After we run the graph, we expect to see exactly 4 checkpoints:
  * empty checkpoint with `START` as the next node to be executed
  * checkpoint with the user input `{'foo': '', 'bar': []}` and `node_a` as the next node to be executed
  * checkpoint with the outputs of `node_a` `{'foo': 'a', 'bar': ['a']}` and `node_b` as the next node to be executed
  * checkpoint with the outputs of `node_b` `{'foo': 'b', 'bar': ['a', 'b']}` and no next nodes to be executed


Note that we `bar` channel values contain outputs from both nodes as we have a reducer for `bar` channel.
### Get state[¶](https://langchain-ai.github.io/langgraph/concepts/persistence/#get-state "Permanent link")
When interacting with the saved graph state, you **must** specify a [thread identifier](https://langchain-ai.github.io/langgraph/concepts/persistence/#threads). You can view the _latest_ state of the graph by calling `graph.get_state(config)`. This will return a `StateSnapshot` object that corresponds to the latest checkpoint associated with the thread ID provided in the config or a checkpoint associated with a checkpoint ID for the thread, if provided.
```
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-2-1)# get the latest state snapshot
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-2-2)config = {"configurable": {"thread_id": "1"}}
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-2-3)graph.get_state(config)
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-2-4)
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-2-5)# get a state snapshot for a specific checkpoint_id
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-2-6)config = {"configurable": {"thread_id": "1", "checkpoint_id": "1ef663ba-28fe-6528-8002-5a559208592c"}}
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-2-7)graph.get_state(config)

```

In our example, the output of `get_state` will look like this:
```
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-3-1)StateSnapshot(
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-3-2)    values={'foo': 'b', 'bar': ['a', 'b']},
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-3-3)    next=(),
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-3-4)    config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1ef663ba-28fe-6528-8002-5a559208592c'}},
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-3-5)    metadata={'source': 'loop', 'writes': {'node_b': {'foo': 'b', 'bar': ['b']}}, 'step': 2},
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-3-6)    created_at='2024-08-29T19:19:38.821749+00:00',
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-3-7)    parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1ef663ba-28f9-6ec4-8001-31981c2c39f8'}}, tasks=()
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-3-8))

```

### Get state history[¶](https://langchain-ai.github.io/langgraph/concepts/persistence/#get-state-history "Permanent link")
You can get the full history of the graph execution for a given thread by calling `graph.get_state_history(config)`. This will return a list of `StateSnapshot` objects associated with the thread ID provided in the config. Importantly, the checkpoints will be ordered chronologically with the most recent checkpoint / `StateSnapshot` being the first in the list.
```
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-4-1)config = {"configurable": {"thread_id": "1"}}
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-4-2)list(graph.get_state_history(config))

```

In our example, the output of `get_state_history` will look like this:
```
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-5-1)[
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-5-2)    StateSnapshot(
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-5-3)        values={'foo': 'b', 'bar': ['a', 'b']},
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-5-4)        next=(),
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-5-5)        config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1ef663ba-28fe-6528-8002-5a559208592c'}},
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-5-6)        metadata={'source': 'loop', 'writes': {'node_b': {'foo': 'b', 'bar': ['b']}}, 'step': 2},
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-5-7)        created_at='2024-08-29T19:19:38.821749+00:00',
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-5-8)        parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1ef663ba-28f9-6ec4-8001-31981c2c39f8'}},
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-5-9)        tasks=(),
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-5-10)    ),
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-5-11)    StateSnapshot(
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-5-12)        values={'foo': 'a', 'bar': ['a']}, next=('node_b',),
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-5-13)        config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1ef663ba-28f9-6ec4-8001-31981c2c39f8'}},
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-5-14)        metadata={'source': 'loop', 'writes': {'node_a': {'foo': 'a', 'bar': ['a']}}, 'step': 1},
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-5-15)        created_at='2024-08-29T19:19:38.819946+00:00',
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-5-16)        parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1ef663ba-28f4-6b4a-8000-ca575a13d36a'}},
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-5-17)        tasks=(PregelTask(id='6fb7314f-f114-5413-a1f3-d37dfe98ff44', name='node_b', error=None, interrupts=()),),
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-5-18)    ),
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-5-19)    StateSnapshot(
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-5-20)        values={'foo': '', 'bar': []},
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-5-21)        next=('node_a',),
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-5-22)        config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1ef663ba-28f4-6b4a-8000-ca575a13d36a'}},
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-5-23)        metadata={'source': 'loop', 'writes': None, 'step': 0},
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-5-24)        created_at='2024-08-29T19:19:38.817813+00:00',
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-5-25)        parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1ef663ba-28f0-6c66-bfff-6723431e8481'}},
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-5-26)        tasks=(PregelTask(id='f1b14528-5ee5-579c-949b-23ef9bfbed58', name='node_a', error=None, interrupts=()),),
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-5-27)    ),
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-5-28)    StateSnapshot(
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-5-29)        values={'bar': []},
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-5-30)        next=('__start__',),
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-5-31)        config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1ef663ba-28f0-6c66-bfff-6723431e8481'}},
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-5-32)        metadata={'source': 'input', 'writes': {'foo': ''}, 'step': -1},
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-5-33)        created_at='2024-08-29T19:19:38.816205+00:00',
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-5-34)        parent_config=None,
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-5-35)        tasks=(PregelTask(id='6d27aa2e-d72b-5504-a36f-8620e54a76dd', name='__start__', error=None, interrupts=()),),
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-5-36)    )
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-5-37)]

```

![State](https://langchain-ai.github.io/langgraph/concepts/img/persistence/get_state.jpg)
### Replay[¶](https://langchain-ai.github.io/langgraph/concepts/persistence/#replay "Permanent link")
It's also possible to play-back a prior graph execution. If we `invoke` a graph with a `thread_id` and a `checkpoint_id`, then we will _re-play_ the previously executed steps _before_ a checkpoint that corresponds to the `checkpoint_id`, and only execute the steps _after_ the checkpoint.
  * `thread_id` is the ID of a thread.
  * `checkpoint_id` is an identifier that refers to a specific checkpoint within a thread.


You must pass these when invoking the graph as part of the `configurable` portion of the config:
```
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-6-1)config = {"configurable": {"thread_id": "1", "checkpoint_id": "0c62ca34-ac19-445d-bbb0-5b4984975b2a"}}
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-6-2)graph.invoke(None, config=config)

```

Importantly, LangGraph knows whether a particular step has been executed previously. If it has, LangGraph simply _re-plays_ that particular step in the graph and does not re-execute the step, but only for the steps _before_ the provided `checkpoint_id`. All of the steps _after_ `checkpoint_id` will be executed (i.e., a new fork), even if they have been executed previously. See this [how to guide on time-travel to learn more about replaying](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/time-travel/).
![Replay](https://langchain-ai.github.io/langgraph/concepts/img/persistence/re_play.png)
### Update state[¶](https://langchain-ai.github.io/langgraph/concepts/persistence/#update-state "Permanent link")
In addition to re-playing the graph from specific `checkpoints`, we can also _edit_ the graph state. We do this using `graph.update_state()`. This method accepts three different arguments:
####  `config`[¶](https://langchain-ai.github.io/langgraph/concepts/persistence/#config "Permanent link")
The config should contain `thread_id` specifying which thread to update. When only the `thread_id` is passed, we update (or fork) the current state. Optionally, if we include `checkpoint_id` field, then we fork that selected checkpoint.
####  `values`[¶](https://langchain-ai.github.io/langgraph/concepts/persistence/#values "Permanent link")
These are the values that will be used to update the state. Note that this update is treated exactly as any update from a node is treated. This means that these values will be passed to the [reducer](https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers) functions, if they are defined for some of the channels in the graph state. This means that `update_state` does NOT automatically overwrite the channel values for every channel, but only for the channels without reducers. Let's walk through an example.
Let's assume you have defined the state of your graph with the following schema (see full example above):
```
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-7-1)fromtypingimport Annotated
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-7-2)fromtyping_extensionsimport TypedDict
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-7-3)fromoperatorimport add
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-7-4)
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-7-5)classState(TypedDict):
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-7-6)    foo: int
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-7-7)    bar: Annotated[list[str], add]

```

Let's now assume the current state of the graph is
```
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-8-1){"foo": 1, "bar": ["a"]}

```

If you update the state as below:
```
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-9-1)graph.update_state(config, {"foo": 2, "bar": ["b"]})

```

Then the new state of the graph will be:
```
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-10-1){"foo": 2, "bar": ["a", "b"]}

```

The `foo` key (channel) is completely changed (because there is no reducer specified for that channel, so `update_state` overwrites it). However, there is a reducer specified for the `bar` key, and so it appends `"b"` to the state of `bar`.
####  `as_node`[¶](https://langchain-ai.github.io/langgraph/concepts/persistence/#as_node "Permanent link")
The final thing you can optionally specify when calling `update_state` is `as_node`. If you provided it, the update will be applied as if it came from node `as_node`. If `as_node` is not provided, it will be set to the last node that updated the state, if not ambiguous. The reason this matters is that the next steps to execute depend on the last node to have given an update, so this can be used to control which node executes next. See this [how to guide on time-travel to learn more about forking state](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/time-travel/).
![Update](https://langchain-ai.github.io/langgraph/concepts/img/persistence/checkpoints_full_story.jpg)
## Memory Store[¶](https://langchain-ai.github.io/langgraph/concepts/persistence/#memory-store "Permanent link")
![Model of shared state](https://langchain-ai.github.io/langgraph/concepts/img/persistence/shared_state.png)
A [state schema](https://langchain-ai.github.io/langgraph/concepts/low_level/#schema) specifies a set of keys that are populated as a graph is executed. As discussed above, state can be written by a checkpointer to a thread at each graph step, enabling state persistence.
But, what if we want to retain some information _across threads_? Consider the case of a chatbot where we want to retain specific information about the user across _all_ chat conversations (e.g., threads) with that user!
With checkpointers alone, we cannot share information across threads. This motivates the need for the [`Store`](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore) interface. As an illustration, we can define an `InMemoryStore` to store information about a user across threads. We simply compile our graph with a checkpointer, as before, and with our new `in_memory_store` variable.
LangGraph API handles stores automatically
When using the LangGraph API, you don't need to implement or configure stores manually. The API handles all storage infrastructure for you behind the scenes.
### Basic Usage[¶](https://langchain-ai.github.io/langgraph/concepts/persistence/#basic-usage "Permanent link")
First, let's showcase this in isolation without using LangGraph.
```
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-11-1)fromlanggraph.store.memoryimport InMemoryStore
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-11-2)in_memory_store = InMemoryStore()

```

Memories are namespaced by a `tuple`, which in this specific example will be `(<user_id>, "memories")`. The namespace can be any length and represent anything, does not have to be user specific.
```
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-12-1)user_id = "1"
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-12-2)namespace_for_memory = (user_id, "memories")

```

We use the `store.put` method to save memories to our namespace in the store. When we do this, we specify the namespace, as defined above, and a key-value pair for the memory: the key is simply a unique identifier for the memory (`memory_id`) and the value (a dictionary) is the memory itself.
```
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-13-1)memory_id = str(uuid.uuid4())
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-13-2)memory = {"food_preference" : "I like pizza"}
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-13-3)in_memory_store.put(namespace_for_memory, memory_id, memory)

```

We can read out memories in our namespace using the `store.search` method, which will return all memories for a given user as a list. The most recent memory is the last in the list.
```
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-14-1)memories = in_memory_store.search(namespace_for_memory)
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-14-2)memories[-1].dict()
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-14-3){'value': {'food_preference': 'I like pizza'},
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-14-4) 'key': '07e0caf4-1631-47b7-b15f-65515d4c1843',
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-14-5) 'namespace': ['1', 'memories'],
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-14-6) 'created_at': '2024-10-02T17:22:31.590602+00:00',
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-14-7) 'updated_at': '2024-10-02T17:22:31.590605+00:00'}

```

Each memory type is a Python class ([`Item`](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.Item)) with certain attributes. We can access it as a dictionary by converting via `.dict` as above. The attributes it has are:
  * `value`: The value (itself a dictionary) of this memory
  * `key`: A unique key for this memory in this namespace
  * `namespace`: A list of strings, the namespace of this memory type
  * `created_at`: Timestamp for when this memory was created
  * `updated_at`: Timestamp for when this memory was updated


### Semantic Search[¶](https://langchain-ai.github.io/langgraph/concepts/persistence/#semantic-search "Permanent link")
Beyond simple retrieval, the store also supports semantic search, allowing you to find memories based on meaning rather than exact matches. To enable this, configure the store with an embedding model:
_API Reference:[init_embeddings](https://python.langchain.com/api_reference/langchain/embeddings/langchain.embeddings.base.init_embeddings.html)_
```
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-15-1)fromlangchain.embeddingsimport init_embeddings
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-15-2)
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-15-3)store = InMemoryStore(
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-15-4)    index={
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-15-5)        "embed": init_embeddings("openai:text-embedding-3-small"),  # Embedding provider
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-15-6)        "dims": 1536,                              # Embedding dimensions
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-15-7)        "fields": ["food_preference", "$"]              # Fields to embed
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-15-8)    }
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-15-9))

```

Now when searching, you can use natural language queries to find relevant memories:
```
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-16-1)# Find memories about food preferences
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-16-2)# (This can be done after putting memories into the store)
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-16-3)memories = store.search(
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-16-4)    namespace_for_memory,
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-16-5)    query="What does the user like to eat?",
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-16-6)    limit=3  # Return top 3 matches
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-16-7))

```

You can control which parts of your memories get embedded by configuring the `fields` parameter or by specifying the `index` parameter when storing memories:
```
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-17-1)# Store with specific fields to embed
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-17-2)store.put(
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-17-3)    namespace_for_memory,
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-17-4)    str(uuid.uuid4()),
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-17-5)    {
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-17-6)        "food_preference": "I love Italian cuisine",
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-17-7)        "context": "Discussing dinner plans"
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-17-8)    },
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-17-9)    index=["food_preference"]  # Only embed "food_preferences" field
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-17-10))
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-17-11)
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-17-12)# Store without embedding (still retrievable, but not searchable)
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-17-13)store.put(
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-17-14)    namespace_for_memory,
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-17-15)    str(uuid.uuid4()),
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-17-16)    {"system_info": "Last updated: 2024-01-01"},
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-17-17)    index=False
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-17-18))

```

### Using in LangGraph[¶](https://langchain-ai.github.io/langgraph/concepts/persistence/#using-in-langgraph "Permanent link")
With this all in place, we use the `in_memory_store` in LangGraph. The `in_memory_store` works hand-in-hand with the checkpointer: the checkpointer saves state to threads, as discussed above, and the `in_memory_store` allows us to store arbitrary information for access _across_ threads. We compile the graph with both the checkpointer and the `in_memory_store` as follows. 
_API Reference:[InMemorySaver](https://langchain-ai.github.io/langgraph/reference/checkpoints/#langgraph.checkpoint.memory.InMemorySaver)_
```
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-18-1)fromlanggraph.checkpoint.memoryimport InMemorySaver
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-18-2)
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-18-3)# We need this because we want to enable threads (conversations)
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-18-4)checkpointer = InMemorySaver()
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-18-5)
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-18-6)# ... Define the graph ...
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-18-7)
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-18-8)# Compile the graph with the checkpointer and store
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-18-9)graph = graph.compile(checkpointer=checkpointer, store=in_memory_store)

```

We invoke the graph with a `thread_id`, as before, and also with a `user_id`, which we'll use to namespace our memories to this particular user as we showed above.
```
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-19-1)# Invoke the graph
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-19-2)user_id = "1"
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-19-3)config = {"configurable": {"thread_id": "1", "user_id": user_id}}
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-19-4)
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-19-5)# First let's just say hi to the AI
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-19-6)for update in graph.stream(
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-19-7)    {"messages": [{"role": "user", "content": "hi"}]}, config, stream_mode="updates"
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-19-8)):
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-19-9)    print(update)

```

We can access the `in_memory_store` and the `user_id` in _any node_ by passing `store: BaseStore` and `config: RunnableConfig` as node arguments. Here's how we might use semantic search in a node to find relevant memories:
```
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-20-1)defupdate_memory(state: MessagesState, config: RunnableConfig, *, store: BaseStore):
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-20-2)
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-20-3)    # Get the user id from the config
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-20-4)    user_id = config["configurable"]["user_id"]
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-20-5)
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-20-6)    # Namespace the memory
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-20-7)    namespace = (user_id, "memories")
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-20-8)
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-20-9)    # ... Analyze conversation and create a new memory
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-20-10)
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-20-11)    # Create a new memory ID
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-20-12)    memory_id = str(uuid.uuid4())
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-20-13)
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-20-14)    # We create a new memory
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-20-15)    store.put(namespace, memory_id, {"memory": memory})

```

As we showed above, we can also access the store in any node and use the `store.search` method to get memories. Recall the the memories are returned as a list of objects that can be converted to a dictionary.
```
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-21-1)memories[-1].dict()
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-21-2){'value': {'food_preference': 'I like pizza'},
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-21-3) 'key': '07e0caf4-1631-47b7-b15f-65515d4c1843',
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-21-4) 'namespace': ['1', 'memories'],
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-21-5) 'created_at': '2024-10-02T17:22:31.590602+00:00',
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-21-6) 'updated_at': '2024-10-02T17:22:31.590605+00:00'}

```

We can access the memories and use them in our model call.
```
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-22-1)defcall_model(state: MessagesState, config: RunnableConfig, *, store: BaseStore):
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-22-2)    # Get the user id from the config
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-22-3)    user_id = config["configurable"]["user_id"]
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-22-4)
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-22-5)    # Namespace the memory
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-22-6)    namespace = (user_id, "memories")
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-22-7)
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-22-8)    # Search based on the most recent message
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-22-9)    memories = store.search(
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-22-10)        namespace,
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-22-11)        query=state["messages"][-1].content,
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-22-12)        limit=3
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-22-13)    )
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-22-14)    info = "\n".join([d.value["memory"] for d in memories])
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-22-15)
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-22-16)    # ... Use memories in the model call

```

If we create a new thread, we can still access the same memories so long as the `user_id` is the same. 
```
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-23-1)# Invoke the graph
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-23-2)config = {"configurable": {"thread_id": "2", "user_id": "1"}}
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-23-3)
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-23-4)# Let's say hi again
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-23-5)for update in graph.stream(
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-23-6)    {"messages": [{"role": "user", "content": "hi, tell me about my memories"}]}, config, stream_mode="updates"
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-23-7)):
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-23-8)    print(update)

```

When we use the LangGraph Platform, either locally (e.g., in LangGraph Studio) or with LangGraph Cloud, the base store is available to use by default and does not need to be specified during graph compilation. To enable semantic search, however, you **do** need to configure the indexing settings in your `langgraph.json` file. For example:
```
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-24-1){
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-24-2)...
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-24-3)"store":{
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-24-4)"index":{
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-24-5)"embed":"openai:text-embeddings-3-small",
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-24-6)"dims":1536,
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-24-7)"fields":["$"]
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-24-8)}
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-24-9)}
[](https://langchain-ai.github.io/langgraph/concepts/persistence/#__codelineno-24-10)}

```

See the [deployment guide](https://langchain-ai.github.io/langgraph/cloud/deployment/semantic_search/) for more details and configuration options.
## Checkpointer libraries[¶](https://langchain-ai.github.io/langgraph/concepts/persistence/#checkpointer-libraries "Permanent link")
Under the hood, checkpointing is powered by checkpointer objects that conform to [BaseCheckpointSaver](https://langchain-ai.github.io/langgraph/reference/checkpoints/#langgraph.checkpoint.base.BaseCheckpointSaver "<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">BaseCheckpointSaver</span>") interface. LangGraph provides several checkpointer implementations, all implemented via standalone, installable libraries:
  * `langgraph-checkpoint`: The base interface for checkpointer savers ([BaseCheckpointSaver](https://langchain-ai.github.io/langgraph/reference/checkpoints/#langgraph.checkpoint.base.BaseCheckpointSaver "<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">BaseCheckpointSaver</span>")) and serialization/deserialization interface ([SerializerProtocol](https://langchain-ai.github.io/langgraph/reference/checkpoints/#langgraph.checkpoint.serde.base.SerializerProtocol "<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">SerializerProtocol</span>")). Includes in-memory checkpointer implementation ([InMemorySaver](https://langchain-ai.github.io/langgraph/reference/checkpoints/#langgraph.checkpoint.memory.InMemorySaver "<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">InMemorySaver</span>")) for experimentation. LangGraph comes with `langgraph-checkpoint` included.
  * `langgraph-checkpoint-sqlite`: An implementation of LangGraph checkpointer that uses SQLite database ([SqliteSaver](https://langchain-ai.github.io/langgraph/reference/checkpoints/#langgraph.checkpoint.sqlite.SqliteSaver "<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">SqliteSaver</span>") / [AsyncSqliteSaver](https://langchain-ai.github.io/langgraph/reference/checkpoints/#langgraph.checkpoint.sqlite.aio.AsyncSqliteSaver "<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">AsyncSqliteSaver</span>")). Ideal for experimentation and local workflows. Needs to be installed separately.
  * `langgraph-checkpoint-postgres`: An advanced checkpointer that uses Postgres database ([PostgresSaver](https://langchain-ai.github.io/langgraph/reference/checkpoints/#langgraph.checkpoint.postgres.PostgresSaver "<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">PostgresSaver</span>") / [AsyncPostgresSaver](https://langchain-ai.github.io/langgraph/reference/checkpoints/#langgraph.checkpoint.postgres.aio.AsyncPostgresSaver "<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">AsyncPostgresSaver</span>")), used in LangGraph Cloud. Ideal for using in production. Needs to be installed separately.


### Checkpointer interface[¶](https://langchain-ai.github.io/langgraph/concepts/persistence/#checkpointer-interface "Permanent link")
Each checkpointer conforms to [BaseCheckpointSaver](https://langchain-ai.github.io/langgraph/reference/checkpoints/#langgraph.checkpoint.base.BaseCheckpointSaver "<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">BaseCheckpointSaver</span>") interface and implements the following methods:
  * `.put` - Store a checkpoint with its configuration and metadata. 
  * `.put_writes` - Store intermediate writes linked to a checkpoint (i.e. [pending writes](https://langchain-ai.github.io/langgraph/concepts/persistence/#pending-writes)). 
  * `.get_tuple` - Fetch a checkpoint tuple using for a given configuration (`thread_id` and `checkpoint_id`). This is used to populate `StateSnapshot` in `graph.get_state()`. 
  * `.list` - List checkpoints that match a given configuration and filter criteria. This is used to populate state history in `graph.get_state_history()`


If the checkpointer is used with asynchronous graph execution (i.e. executing the graph via `.ainvoke`, `.astream`, `.abatch`), asynchronous versions of the above methods will be used (`.aput`, `.aput_writes`, `.aget_tuple`, `.alist`).
Note
For running your graph asynchronously, you can use `InMemorySaver`, or async versions of Sqlite/Postgres checkpointers -- `AsyncSqliteSaver` / `AsyncPostgresSaver` checkpointers.
### Serializer[¶](https://langchain-ai.github.io/langgraph/concepts/persistence/#serializer "Permanent link")
When checkpointers save the graph state, they need to serialize the channel values in the state. This is done using serializer objects. `langgraph_checkpoint` defines [protocol](https://langchain-ai.github.io/langgraph/reference/checkpoints/#langgraph.checkpoint.serde.base.SerializerProtocol "<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">SerializerProtocol</span>") for implementing serializers provides a default implementation ([JsonPlusSerializer](https://langchain-ai.github.io/langgraph/reference/checkpoints/#langgraph.checkpoint.serde.jsonplus.JsonPlusSerializer "<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">JsonPlusSerializer</span>")) that handles a wide variety of types, including LangChain and LangGraph primitives, datetimes, enums and more.
## Capabilities[¶](https://langchain-ai.github.io/langgraph/concepts/persistence/#capabilities "Permanent link")
### Human-in-the-loop[¶](https://langchain-ai.github.io/langgraph/concepts/persistence/#human-in-the-loop "Permanent link")
First, checkpointers facilitate [human-in-the-loop workflows](https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/#human-in-the-loop) workflows by allowing humans to inspect, interrupt, and approve graph steps. Checkpointers are needed for these workflows as the human has to be able to view the state of a graph at any point in time, and the graph has to be to resume execution after the human has made any updates to the state. See [these how-to guides](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/breakpoints/) for concrete examples.
### Memory[¶](https://langchain-ai.github.io/langgraph/concepts/persistence/#memory "Permanent link")
Second, checkpointers allow for ["memory"](https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/#memory) between interactions. In the case of repeated human interactions (like conversations) any follow up messages can be sent to that thread, which will retain its memory of previous ones. See [this how-to guide](https://langchain-ai.github.io/langgraph/concepts/how-tos/memory/manage-conversation-history.ipynb) for an end-to-end example on how to add and manage conversation memory using checkpointers.
### Time Travel[¶](https://langchain-ai.github.io/langgraph/concepts/persistence/#time-travel "Permanent link")
Third, checkpointers allow for ["time travel"](https://langchain-ai.github.io/langgraph/concepts/time-travel/), allowing users to replay prior graph executions to review and / or debug specific graph steps. In addition, checkpointers make it possible to fork the graph state at arbitrary checkpoints to explore alternative trajectories.
### Fault-tolerance[¶](https://langchain-ai.github.io/langgraph/concepts/persistence/#fault-tolerance "Permanent link")
Lastly, checkpointing also provides fault-tolerance and error recovery: if one or more nodes fail at a given superstep, you can restart your graph from the last successful step. Additionally, when a graph node fails mid-execution at a given superstep, LangGraph stores pending checkpoint writes from any other nodes that completed successfully at that superstep, so that whenever we resume graph execution from that superstep we don't re-run the successful nodes.
#### Pending writes[¶](https://langchain-ai.github.io/langgraph/concepts/persistence/#pending-writes "Permanent link")
Additionally, when a graph node fails mid-execution at a given superstep, LangGraph stores pending checkpoint writes from any other nodes that completed successfully at that superstep, so that whenever we resume graph execution from that superstep we don't re-run the successful nodes.
Was this page helpful? 
Thanks for your feedback! 
Thanks for your feedback! Please help us improve this page by adding to the discussion below. 
[ Previous  Stream outputs  ](https://langchain-ai.github.io/langgraph/how-tos/streaming/) [ Next  Durable Execution  ](https://langchain-ai.github.io/langgraph/concepts/durable_execution/)
Copyright © 2025 LangChain, Inc | [Consent Preferences](https://langchain-ai.github.io/langgraph/concepts/persistence/#__consent)
Made with [ Material for MkDocs Insiders ](https://squidfunk.github.io/mkdocs-material/)
[ ](https://langchain-ai.github.io/langgraphjs/ "langchain-ai.github.io") [ ](https://github.com/langchain-ai/langgraph "github.com") [ ](https://twitter.com/LangChainAI "twitter.com")
#### Cookie consent
We use cookies to recognize your repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find what they're searching for. **Clicking "Accept" makes our documentation better. Thank you!** ❤️
  *   * 

Accept Reject
