[ Skip to content ](https://langchain-ai.github.io/langgraph/concepts/memory/#memory)
**We are growing and hiring for multiple roles for LangChain, LangGraph and LangSmith.[ Join our team!](https://www.langchain.com/careers)**
[ ![logo](https://langchain-ai.github.io/langgraph/static/wordmark_dark.svg) ![logo](https://langchain-ai.github.io/langgraph/static/wordmark_light.svg) ](https://langchain-ai.github.io/langgraph/ "LangGraph")
LangGraph 
Overview 
[ ](https://langchain-ai.github.io/langgraph/concepts/memory/?q= "Share")
Type to start searching
[ GitHub  ](https://github.com/langchain-ai/langgraph "Go to repository")
  * [ Guides ](https://langchain-ai.github.io/langgraph/)
  * [ Reference ](https://langchain-ai.github.io/langgraph/reference/)
  * [ Examples ](https://langchain-ai.github.io/langgraph/tutorials/rag/langgraph_agentic_rag/)
  * [ Resources ](https://langchain-ai.github.io/langgraph/concepts/faq/)


[ ![logo](https://langchain-ai.github.io/langgraph/static/wordmark_dark.svg) ![logo](https://langchain-ai.github.io/langgraph/static/wordmark_light.svg) ](https://langchain-ai.github.io/langgraph/ "LangGraph") LangGraph 
[ GitHub  ](https://github.com/langchain-ai/langgraph "Go to repository")
  * [ Guides  ](https://langchain-ai.github.io/langgraph/)
    * Get started 
      * [ Quickstart  ](https://langchain-ai.github.io/langgraph/agents/agents/)
      * [ LangGraph basics  ](https://langchain-ai.github.io/langgraph/concepts/why-langgraph/)
      * [ Deployment  ](https://langchain-ai.github.io/langgraph/tutorials/deployment/)
    * Prebuilt agents 
      * [ Overview  ](https://langchain-ai.github.io/langgraph/agents/overview/)
      * [ Running agents  ](https://langchain-ai.github.io/langgraph/agents/run_agents/)
      * [ Streaming  ](https://langchain-ai.github.io/langgraph/agents/streaming/)
      * [ Models  ](https://langchain-ai.github.io/langgraph/agents/models/)
      * [ Tools  ](https://langchain-ai.github.io/langgraph/agents/tools/)
      * [ MCP Integration  ](https://langchain-ai.github.io/langgraph/agents/mcp/)
      * [ Context  ](https://langchain-ai.github.io/langgraph/agents/context/)
      * [ Memory  ](https://langchain-ai.github.io/langgraph/agents/memory/)
      * [ Human-in-the-loop  ](https://langchain-ai.github.io/langgraph/agents/human-in-the-loop/)
      * [ Multi-agent  ](https://langchain-ai.github.io/langgraph/agents/multi-agent/)
      * [ Evals  ](https://langchain-ai.github.io/langgraph/agents/evals/)
      * [ Deployment  ](https://langchain-ai.github.io/langgraph/agents/deployment/)
      * [ UI  ](https://langchain-ai.github.io/langgraph/agents/ui/)
    * LangGraph framework 
      * [ Agent architectures  ](https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/)
      * [ Graphs  ](https://langchain-ai.github.io/langgraph/concepts/low_level/)
      * [ Streaming  ](https://langchain-ai.github.io/langgraph/concepts/streaming/)
      * [ Persistence  ](https://langchain-ai.github.io/langgraph/concepts/persistence/)
      * Memory 
        * Overview  [ Overview  ](https://langchain-ai.github.io/langgraph/concepts/memory/)
          * [ What is Memory?  ](https://langchain-ai.github.io/langgraph/concepts/memory/#what-is-memory)
          * [ Short-term memory  ](https://langchain-ai.github.io/langgraph/concepts/memory/#short-term-memory)
            * [ Managing long conversation history  ](https://langchain-ai.github.io/langgraph/concepts/memory/#managing-long-conversation-history)
            * [ Editing message lists  ](https://langchain-ai.github.io/langgraph/concepts/memory/#editing-message-lists)
            * [ Summarizing past conversations  ](https://langchain-ai.github.io/langgraph/concepts/memory/#summarizing-past-conversations)
            * [ Knowing when to remove messages  ](https://langchain-ai.github.io/langgraph/concepts/memory/#knowing-when-to-remove-messages)
          * [ Long-term memory  ](https://langchain-ai.github.io/langgraph/concepts/memory/#long-term-memory)
            * [ Storing memories  ](https://langchain-ai.github.io/langgraph/concepts/memory/#storing-memories)
            * [ Framework for thinking about long-term memory  ](https://langchain-ai.github.io/langgraph/concepts/memory/#framework-for-thinking-about-long-term-memory)
          * [ Memory types  ](https://langchain-ai.github.io/langgraph/concepts/memory/#memory-types)
            * [ Semantic Memory  ](https://langchain-ai.github.io/langgraph/concepts/memory/#semantic-memory)
              * [ Profile  ](https://langchain-ai.github.io/langgraph/concepts/memory/#profile)
              * [ Collection  ](https://langchain-ai.github.io/langgraph/concepts/memory/#collection)
            * [ Episodic Memory  ](https://langchain-ai.github.io/langgraph/concepts/memory/#episodic-memory)
            * [ Procedural Memory  ](https://langchain-ai.github.io/langgraph/concepts/memory/#procedural-memory)
          * [ Writing memories  ](https://langchain-ai.github.io/langgraph/concepts/memory/#writing-memories)
            * [ Writing memories in the hot path  ](https://langchain-ai.github.io/langgraph/concepts/memory/#writing-memories-in-the-hot-path)
            * [ Writing memories in the background  ](https://langchain-ai.github.io/langgraph/concepts/memory/#writing-memories-in-the-background)
        * [ Manage memory  ](https://langchain-ai.github.io/langgraph/how-tos/memory/)
      * [ Human-in-the-loop  ](https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/)
      * [ Breakpoints  ](https://langchain-ai.github.io/langgraph/concepts/breakpoints/)
      * [ Time travel  ](https://langchain-ai.github.io/langgraph/concepts/time-travel/)
      * [ Tools  ](https://langchain-ai.github.io/langgraph/concepts/tools/)
      * [ Subgraphs  ](https://langchain-ai.github.io/langgraph/concepts/subgraphs/)
      * [ Multi-agent  ](https://langchain-ai.github.io/langgraph/concepts/multi_agent/)
      * [ Functional API  ](https://langchain-ai.github.io/langgraph/concepts/functional_api/)
      * [ LangGraph's Runtime (Pregel)  ](https://langchain-ai.github.io/langgraph/concepts/pregel/)
      * [ Other  ](https://langchain-ai.github.io/langgraph/how-tos/async/)
    * LangGraph Platform 
      * [ Overview  ](https://langchain-ai.github.io/langgraph/concepts/langgraph_platform/)
      * [ Get started  ](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/)
      * [ Components  ](https://langchain-ai.github.io/langgraph/concepts/langgraph_components/)
      * [ Data management  ](https://langchain-ai.github.io/langgraph/cloud/deployment/semantic_search/)
      * [ Authentication & access control  ](https://langchain-ai.github.io/langgraph/concepts/auth/)
      * [ Assistants  ](https://langchain-ai.github.io/langgraph/concepts/assistants/)
      * [ Threads  ](https://langchain-ai.github.io/langgraph/cloud/concepts/threads/)
      * [ Runs  ](https://langchain-ai.github.io/langgraph/cloud/concepts/runs/)
      * [ Streaming  ](https://langchain-ai.github.io/langgraph/cloud/concepts/streaming/)
      * [ Human-in-the-loop  ](https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_breakpoint/)
      * [ MCP  ](https://langchain-ai.github.io/langgraph/concepts/server-mcp/)
      * [ Double-texting  ](https://langchain-ai.github.io/langgraph/concepts/double_texting/)
      * [ Webhooks  ](https://langchain-ai.github.io/langgraph/cloud/concepts/webhooks/)
      * [ Cron Jobs  ](https://langchain-ai.github.io/langgraph/cloud/concepts/cron_jobs/)
      * [ Server Customization  ](https://langchain-ai.github.io/langgraph/how-tos/http/custom_lifespan/)
      * [ Deployment  ](https://langchain-ai.github.io/langgraph/concepts/deployment_options/)
  * [ Reference  ](https://langchain-ai.github.io/langgraph/reference/)
  * [ Examples  ](https://langchain-ai.github.io/langgraph/tutorials/rag/langgraph_agentic_rag/)
  * [ Resources  ](https://langchain-ai.github.io/langgraph/concepts/faq/)


  * [ What is Memory?  ](https://langchain-ai.github.io/langgraph/concepts/memory/#what-is-memory)
  * [ Short-term memory  ](https://langchain-ai.github.io/langgraph/concepts/memory/#short-term-memory)
    * [ Managing long conversation history  ](https://langchain-ai.github.io/langgraph/concepts/memory/#managing-long-conversation-history)
    * [ Editing message lists  ](https://langchain-ai.github.io/langgraph/concepts/memory/#editing-message-lists)
    * [ Summarizing past conversations  ](https://langchain-ai.github.io/langgraph/concepts/memory/#summarizing-past-conversations)
    * [ Knowing when to remove messages  ](https://langchain-ai.github.io/langgraph/concepts/memory/#knowing-when-to-remove-messages)
  * [ Long-term memory  ](https://langchain-ai.github.io/langgraph/concepts/memory/#long-term-memory)
    * [ Storing memories  ](https://langchain-ai.github.io/langgraph/concepts/memory/#storing-memories)
    * [ Framework for thinking about long-term memory  ](https://langchain-ai.github.io/langgraph/concepts/memory/#framework-for-thinking-about-long-term-memory)
  * [ Memory types  ](https://langchain-ai.github.io/langgraph/concepts/memory/#memory-types)
    * [ Semantic Memory  ](https://langchain-ai.github.io/langgraph/concepts/memory/#semantic-memory)
      * [ Profile  ](https://langchain-ai.github.io/langgraph/concepts/memory/#profile)
      * [ Collection  ](https://langchain-ai.github.io/langgraph/concepts/memory/#collection)
    * [ Episodic Memory  ](https://langchain-ai.github.io/langgraph/concepts/memory/#episodic-memory)
    * [ Procedural Memory  ](https://langchain-ai.github.io/langgraph/concepts/memory/#procedural-memory)
  * [ Writing memories  ](https://langchain-ai.github.io/langgraph/concepts/memory/#writing-memories)
    * [ Writing memories in the hot path  ](https://langchain-ai.github.io/langgraph/concepts/memory/#writing-memories-in-the-hot-path)
    * [ Writing memories in the background  ](https://langchain-ai.github.io/langgraph/concepts/memory/#writing-memories-in-the-background)


  1. [ Guides  ](https://langchain-ai.github.io/langgraph/)
  2. [ LangGraph framework  ](https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/)
  3. [ Memory  ](https://langchain-ai.github.io/langgraph/concepts/memory/)

[ ](https://github.com/langchain-ai/langgraph/edit/main/docs/docs/concepts/memory.md "Edit this page")
# Memory[¶](https://langchain-ai.github.io/langgraph/concepts/memory/#memory "Permanent link")
## What is Memory?[¶](https://langchain-ai.github.io/langgraph/concepts/memory/#what-is-memory "Permanent link")
[Memory](https://pmc.ncbi.nlm.nih.gov/articles/PMC10410470/) is a cognitive function that allows people to store, retrieve, and use information to understand their present and future. Consider the frustration of working with a colleague who forgets everything you tell them, requiring constant repetition! As AI agents undertake more complex tasks involving numerous user interactions, equipping them with memory becomes equally crucial for efficiency and user satisfaction. With memory, agents can learn from feedback and adapt to users' preferences. This guide covers two types of memory based on recall scope:
**Short-term memory** , or [thread](https://langchain-ai.github.io/langgraph/concepts/persistence/#threads)-scoped memory, can be recalled at any time **from within** a single conversational thread with a user. LangGraph manages short-term memory as a part of your agent's [state](https://langchain-ai.github.io/langgraph/concepts/low_level/#state). State is persisted to a database using a [checkpointer](https://langchain-ai.github.io/langgraph/concepts/persistence/#checkpoints) so the thread can be resumed at any time. Short-term memory updates when the graph is invoked or a step is completed, and the State is read at the start of each step.
**Long-term memory** is shared **across** conversational threads. It can be recalled _at any time_ and **in any thread**. Memories are scoped to any custom namespace, not just within a single thread ID. LangGraph provides [stores](https://langchain-ai.github.io/langgraph/concepts/persistence/#memory-store) ([reference doc](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore)) to let you save and recall long-term memories.
Both are important to understand and implement for your application.
![](https://langchain-ai.github.io/langgraph/concepts/img/memory/short-vs-long.png)
## Short-term memory[¶](https://langchain-ai.github.io/langgraph/concepts/memory/#short-term-memory "Permanent link")
Short-term memory lets your application remember previous interactions within a single [thread](https://langchain-ai.github.io/langgraph/concepts/persistence/#threads) or conversation. A [thread](https://langchain-ai.github.io/langgraph/concepts/persistence/#threads) organizes multiple interactions in a session, similar to the way email groups messages in a single conversation.
LangGraph manages short-term memory as part of the agent's state, persisted via thread-scoped checkpoints. This state can normally include the conversation history along with other stateful data, such as uploaded files, retrieved documents, or generated artifacts. By storing these in the graph's state, the bot can access the full context for a given conversation while maintaining separation between different threads.
Since conversation history is the most common form of representing short-term memory, in the next section, we will cover techniques for managing conversation history when the list of messages becomes **long**. If you want to stick to the high-level concepts, continue on to the [long-term memory](https://langchain-ai.github.io/langgraph/concepts/memory/#long-term-memory) section.
### Managing long conversation history[¶](https://langchain-ai.github.io/langgraph/concepts/memory/#managing-long-conversation-history "Permanent link")
Long conversations pose a challenge to today's LLMs. The full history may not even fit inside an LLM's context window, resulting in an irrecoverable error. Even _if_ your LLM technically supports the full context length, most LLMs still perform poorly over long contexts. They get "distracted" by stale or off-topic content, all while suffering from slower response times and higher costs.
Managing short-term memory is an exercise of balancing [precision & recall](https://en.wikipedia.org/wiki/Precision_and_recall#:~:text=Precision%20can%20be%20seen%20as,irrelevant%20ones%20are%20also%20returned) with your application's other performance requirements (latency & cost). As always, it's important to think critically about how you represent information for your LLM and to look at your data. We cover a few common techniques for managing message lists below and hope to provide sufficient context for you to pick the best tradeoffs for your application:
  * [Editing message lists](https://langchain-ai.github.io/langgraph/concepts/memory/#editing-message-lists): How to think about trimming and filtering a list of messages before passing to language model.
  * [Summarizing past conversations](https://langchain-ai.github.io/langgraph/concepts/memory/#summarizing-past-conversations): A common technique to use when you don't just want to filter the list of messages.


### Editing message lists[¶](https://langchain-ai.github.io/langgraph/concepts/memory/#editing-message-lists "Permanent link")
Chat models accept context using [messages](https://python.langchain.com/docs/concepts/#messages), which include developer provided instructions (a system message) and user inputs (human messages). In chat applications, messages alternate between human inputs and model responses, resulting in a list of messages that grows longer over time. Because context windows are limited and token-rich message lists can be costly, many applications can benefit from using techniques to manually remove or forget stale information.
![](https://langchain-ai.github.io/langgraph/concepts/img/memory/filter.png)
The most direct approach is to remove old messages from a list (similar to a [least-recently used cache](https://en.wikipedia.org/wiki/Page_replacement_algorithm#Least_recently_used)).
The typical technique for deleting content from a list in LangGraph is to return an update from a node telling the system to delete some portion of the list. You get to define what this update looks like, but a common approach would be to let you return an object or dictionary specifying which values to retain.
```
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-0-1)defmanage_list(existing: list, updates: Union[list, dict]):
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-0-2)    if isinstance(updates, list):
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-0-3)        # Normal case, add to the history
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-0-4)        return existing + updates
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-0-5)    elif isinstance(updates, dict) and updates["type"] == "keep":
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-0-6)        # You get to decide what this looks like.
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-0-7)        # For example, you could simplify and just accept a string "DELETE"
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-0-8)        # and clear the entire list.
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-0-9)        return existing[updates["from"]:updates["to"]]
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-0-10)    # etc. We define how to interpret updates
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-0-11)
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-0-12)classState(TypedDict):
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-0-13)    my_list: Annotated[list, manage_list]
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-0-14)
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-0-15)defmy_node(state: State):
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-0-16)    return {
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-0-17)        # We return an update for the field "my_list" saying to
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-0-18)        # keep only values from index -5 to the end (deleting the rest)
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-0-19)        "my_list": {"type": "keep", "from": -5, "to": None}
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-0-20)    }

```

LangGraph will call the `manage_list` "[reducer](https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers)" function any time an update is returned under the key "my_list". Within that function, we define what types of updates to accept. Typically, messages will be added to the existing list (the conversation will grow); however, we've also added support to accept a dictionary that lets you "keep" certain parts of the state. This lets you programmatically drop old message context.
Another common approach is to let you return a list of "remove" objects that specify the IDs of all messages to delete. If you're using the LangChain messages and the [`add_messages`](https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.message.add_messages) reducer (or `MessagesState`, which uses the same underlying functionality) in LangGraph, you can do this using a `RemoveMessage`.
_API Reference:[RemoveMessage](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.modifier.RemoveMessage.html) | [AIMessage](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.ai.AIMessage.html) | [add_messages](https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.message.add_messages)_
```
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-1-1)fromlangchain_core.messagesimport RemoveMessage, AIMessage
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-1-2)fromlanggraph.graphimport add_messages
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-1-3)# ... other imports
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-1-4)
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-1-5)classState(TypedDict):
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-1-6)    # add_messages will default to upserting messages by ID to the existing list
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-1-7)    # if a RemoveMessage is returned, it will delete the message in the list by ID
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-1-8)    messages: Annotated[list, add_messages]
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-1-9)
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-1-10)defmy_node_1(state: State):
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-1-11)    # Add an AI message to the `messages` list in the state
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-1-12)    return {"messages": [AIMessage(content="Hi")]}
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-1-13)
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-1-14)defmy_node_2(state: State):
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-1-15)    # Delete all but the last 2 messages from the `messages` list in the state
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-1-16)    delete_messages = [RemoveMessage(id=m.id) for m in state['messages'][:-2]]
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-1-17)    return {"messages": delete_messages}

```

In the example above, the `add_messages` reducer allows us to [append](https://langchain-ai.github.io/langgraph/concepts/low_level/#serialization) new messages to the `messages` state key as shown in `my_node_1`. When it sees a `RemoveMessage`, it will delete the message with that ID from the list (and the RemoveMessage will then be discarded). For more information on LangChain-specific message handling, check out [this how-to on using `RemoveMessage` ](https://langchain-ai.github.io/langgraph/how-tos/memory/delete-messages/).
See this how-to [guide](https://langchain-ai.github.io/langgraph/how-tos/memory/manage-conversation-history/) and module 2 from our [LangChain Academy](https://github.com/langchain-ai/langchain-academy/tree/main/module-2) course for example usage.
### Summarizing past conversations[¶](https://langchain-ai.github.io/langgraph/concepts/memory/#summarizing-past-conversations "Permanent link")
The problem with trimming or removing messages, as shown above, is that we may lose information from culling of the message queue. Because of this, some applications benefit from a more sophisticated approach of summarizing the message history using a chat model.
![](https://langchain-ai.github.io/langgraph/concepts/img/memory/summary.png)
Simple prompting and orchestration logic can be used to achieve this. As an example, in LangGraph we can extend the [MessagesState](https://langchain-ai.github.io/langgraph/concepts/low_level/#working-with-messages-in-graph-state) to include a `summary` key.
```
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-2-1)fromlanggraph.graphimport MessagesState
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-2-2)classState(MessagesState):
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-2-3)    summary: str

```

Then, we can generate a summary of the chat history, using any existing summary as context for the next summary. This `summarize_conversation` node can be called after some number of messages have accumulated in the `messages` state key.
```
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-3-1)defsummarize_conversation(state: State):
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-3-2)
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-3-3)    # First, we get any existing summary
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-3-4)    summary = state.get("summary", "")
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-3-5)
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-3-6)    # Create our summarization prompt
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-3-7)    if summary:
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-3-8)
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-3-9)        # A summary already exists
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-3-10)        summary_message = (
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-3-11)            f"This is a summary of the conversation to date: {summary}\n\n"
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-3-12)            "Extend the summary by taking into account the new messages above:"
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-3-13)        )
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-3-14)
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-3-15)    else:
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-3-16)        summary_message = "Create a summary of the conversation above:"
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-3-17)
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-3-18)    # Add prompt to our history
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-3-19)    messages = state["messages"] + [HumanMessage(content=summary_message)]
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-3-20)    response = model.invoke(messages)
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-3-21)
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-3-22)    # Delete all but the 2 most recent messages
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-3-23)    delete_messages = [RemoveMessage(id=m.id) for m in state["messages"][:-2]]
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-3-24)    return {"summary": response.content, "messages": delete_messages}

```

See this how-to [here](https://langchain-ai.github.io/langgraph/how-tos/memory/add-summary-conversation-history/) and module 2 from our [LangChain Academy](https://github.com/langchain-ai/langchain-academy/tree/main/module-2) course for example usage.
### Knowing **when** to remove messages[¶](https://langchain-ai.github.io/langgraph/concepts/memory/#knowing-when-to-remove-messages "Permanent link")
Most LLMs have a maximum supported context window (denominated in tokens). A simple way to decide when to truncate messages is to count the tokens in the message history and truncate whenever it approaches that limit. Naive truncation is straightforward to implement on your own, though there are a few "gotchas". Some model APIs further restrict the sequence of message types (must start with human message, cannot have consecutive messages of the same type, etc.). If you're using LangChain, you can use the [`trim_messages`](https://python.langchain.com/docs/how_to/trim_messages/#trimming-based-on-token-count) utility and specify the number of tokens to keep from the list, as well as the `strategy` (e.g., keep the last `max_tokens`) to use for handling the boundary.
Below is an example.
_API Reference:[trim_messages](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.utils.trim_messages.html)_
```
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-4-1)fromlangchain_core.messagesimport trim_messages
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-4-2)trim_messages(
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-4-3)    messages,
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-4-4)    # Keep the last <= n_count tokens of the messages.
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-4-5)    strategy="last",
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-4-6)    # Remember to adjust based on your model
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-4-7)    # or else pass a custom token_encoder
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-4-8)    token_counter=ChatOpenAI(model="gpt-4"),
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-4-9)    # Remember to adjust based on the desired conversation
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-4-10)    # length
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-4-11)    max_tokens=45,
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-4-12)    # Most chat models expect that chat history starts with either:
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-4-13)    # (1) a HumanMessage or
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-4-14)    # (2) a SystemMessage followed by a HumanMessage
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-4-15)    start_on="human",
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-4-16)    # Most chat models expect that chat history ends with either:
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-4-17)    # (1) a HumanMessage or
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-4-18)    # (2) a ToolMessage
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-4-19)    end_on=("human", "tool"),
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-4-20)    # Usually, we want to keep the SystemMessage
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-4-21)    # if it's present in the original history.
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-4-22)    # The SystemMessage has special instructions for the model.
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-4-23)    include_system=True,
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-4-24))

```

## Long-term memory[¶](https://langchain-ai.github.io/langgraph/concepts/memory/#long-term-memory "Permanent link")
Long-term memory in LangGraph allows systems to retain information across different conversations or sessions. Unlike short-term memory, which is **thread-scoped** , long-term memory is saved within custom "namespaces."
### Storing memories[¶](https://langchain-ai.github.io/langgraph/concepts/memory/#storing-memories "Permanent link")
LangGraph stores long-term memories as JSON documents in a [store](https://langchain-ai.github.io/langgraph/concepts/persistence/#memory-store) ([reference doc](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore)). Each memory is organized under a custom `namespace` (similar to a folder) and a distinct `key` (like a filename). Namespaces often include user or org IDs or other labels that makes it easier to organize information. This structure enables hierarchical organization of memories. Cross-namespace searching is then supported through content filters. See the example below for an example.
```
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-5-1)fromlanggraph.store.memoryimport InMemoryStore
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-5-2)
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-5-3)
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-5-4)defembed(texts: list[str]) -> list[list[float]]:
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-5-5)    # Replace with an actual embedding function or LangChain embeddings object
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-5-6)    return [[1.0, 2.0] * len(texts)]
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-5-7)
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-5-8)
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-5-9)# InMemoryStore saves data to an in-memory dictionary. Use a DB-backed store in production use.
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-5-10)store = InMemoryStore(index={"embed": embed, "dims": 2})
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-5-11)user_id = "my-user"
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-5-12)application_context = "chitchat"
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-5-13)namespace = (user_id, application_context)
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-5-14)store.put(
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-5-15)    namespace,
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-5-16)    "a-memory",
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-5-17)    {
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-5-18)        "rules": [
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-5-19)            "User likes short, direct language",
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-5-20)            "User only speaks English & python",
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-5-21)        ],
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-5-22)        "my-key": "my-value",
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-5-23)    },
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-5-24))
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-5-25)# get the "memory" by ID
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-5-26)item = store.get(namespace, "a-memory")
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-5-27)# search for "memories" within this namespace, filtering on content equivalence, sorted by vector similarity
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-5-28)items = store.search(
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-5-29)    namespace, filter={"my-key": "my-value"}, query="language preferences"
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-5-30))

```

### Framework for thinking about long-term memory[¶](https://langchain-ai.github.io/langgraph/concepts/memory/#framework-for-thinking-about-long-term-memory "Permanent link")
Long-term memory is a complex challenge without a one-size-fits-all solution. However, the following questions provide a structure framework to help you navigate the different techniques:
**What is the type of memory?**
Humans use memories to remember [facts](https://en.wikipedia.org/wiki/Semantic_memory), [experiences](https://en.wikipedia.org/wiki/Episodic_memory), and [rules](https://en.wikipedia.org/wiki/Procedural_memory). AI agents can use memory in the same ways. For example, AI agents can use memory to remember specific facts about a user to accomplish a task. We expand on several types of memories in the [section below](https://langchain-ai.github.io/langgraph/concepts/memory/#memory-types).
**When do you want to update memories?**
Memory can be updated as part of an agent's application logic (e.g. "on the hot path"). In this case, the agent typically decides to remember facts before responding to a user. Alternatively, memory can be updated as a background task (logic that runs in the background / asynchronously and generates memories). We explain the tradeoffs between these approaches in the [section below](https://langchain-ai.github.io/langgraph/concepts/memory/#writing-memories).
## Memory types[¶](https://langchain-ai.github.io/langgraph/concepts/memory/#memory-types "Permanent link")
Different applications require various types of memory. Although the analogy isn't perfect, examining [human memory types](https://www.psychologytoday.com/us/basics/memory/types-of-memory?ref=blog.langchain.dev) can be insightful. Some research (e.g., the [CoALA paper](https://arxiv.org/pdf/2309.02427)) have even mapped these human memory types to those used in AI agents.
Memory Type | What is Stored | Human Example | Agent Example  
---|---|---|---  
Semantic | Facts | Things I learned in school | Facts about a user  
Episodic | Experiences | Things I did | Past agent actions  
Procedural | Instructions | Instincts or motor skills | Agent system prompt  
### Semantic Memory[¶](https://langchain-ai.github.io/langgraph/concepts/memory/#semantic-memory "Permanent link")
[Semantic memory](https://en.wikipedia.org/wiki/Semantic_memory), both in humans and AI agents, involves the retention of specific facts and concepts. In humans, it can include information learned in school and the understanding of concepts and their relationships. For AI agents, semantic memory is often used to personalize applications by remembering facts or concepts from past interactions. 
> Note: Not to be confused with "semantic search" which is a technique for finding similar content using "meaning" (usually as embeddings). Semantic memory is a term from psychology, referring to storing facts and knowledge, while semantic search is a method for retrieving information based on meaning rather than exact matches.
#### Profile[¶](https://langchain-ai.github.io/langgraph/concepts/memory/#profile "Permanent link")
Semantic memories can be managed in different ways. For example, memories can be a single, continuously updated "profile" of well-scoped and specific information about a user, organization, or other entity (including the agent itself). A profile is generally just a JSON document with various key-value pairs you've selected to represent your domain. 
When remembering a profile, you will want to make sure that you are **updating** the profile each time. As a result, you will want to pass in the previous profile and [ask the model to generate a new profile](https://github.com/langchain-ai/memory-template) (or some [JSON patch](https://github.com/hinthornw/trustcall) to apply to the old profile). This can be become error-prone as the profile gets larger, and may benefit from splitting a profile into multiple documents or **strict** decoding when generating documents to ensure the memory schemas remains valid.
![](https://langchain-ai.github.io/langgraph/concepts/img/memory/update-profile.png)
#### Collection[¶](https://langchain-ai.github.io/langgraph/concepts/memory/#collection "Permanent link")
Alternatively, memories can be a collection of documents that are continuously updated and extended over time. Each individual memory can be more narrowly scoped and easier to generate, which means that you're less likely to **lose** information over time. It's easier for an LLM to generate _new_ objects for new information than reconcile new information with an existing profile. As a result, a document collection tends to lead to [higher recall downstream](https://en.wikipedia.org/wiki/Precision_and_recall).
However, this shifts some complexity memory updating. The model must now _delete_ or _update_ existing items in the list, which can be tricky. In addition, some models may default to over-inserting and others may default to over-updating. See the [Trustcall](https://github.com/hinthornw/trustcall) package for one way to manage this and consider evaluation (e.g., with a tool like [LangSmith](https://docs.smith.langchain.com/tutorials/Developers/evaluation)) to help you tune the behavior.
Working with document collections also shifts complexity to memory **search** over the list. The `Store` currently supports both [semantic search](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.SearchOp.query) and [filtering by content](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.SearchOp.filter).
Finally, using a collection of memories can make it challenging to provide comprehensive context to the model. While individual memories may follow a specific schema, this structure might not capture the full context or relationships between memories. As a result, when using these memories to generate responses, the model may lack important contextual information that would be more readily available in a unified profile approach.
![](https://langchain-ai.github.io/langgraph/concepts/img/memory/update-list.png)
Regardless of memory management approach, the central point is that the agent will use the semantic memories to [ground its responses](https://python.langchain.com/docs/concepts/rag/), which often leads to more personalized and relevant interactions.
### Episodic Memory[¶](https://langchain-ai.github.io/langgraph/concepts/memory/#episodic-memory "Permanent link")
[Episodic memory](https://en.wikipedia.org/wiki/Episodic_memory), in both humans and AI agents, involves recalling past events or actions. The [CoALA paper](https://arxiv.org/pdf/2309.02427) frames this well: facts can be written to semantic memory, whereas _experiences_ can be written to episodic memory. For AI agents, episodic memory is often used to help an agent remember how to accomplish a task. 
In practice, episodic memories are often implemented through [few-shot example prompting](https://python.langchain.com/docs/concepts/few_shot_prompting/), where agents learn from past sequences to perform tasks correctly. Sometimes it's easier to "show" than "tell" and LLMs learn well from examples. Few-shot learning lets you ["program"](https://x.com/karpathy/status/1627366413840322562) your LLM by updating the prompt with input-output examples to illustrate the intended behavior. While various [best-practices](https://python.langchain.com/docs/concepts/#1-generating-examples) can be used to generate few-shot examples, often the challenge lies in selecting the most relevant examples based on user input.
Note that the memory [store](https://langchain-ai.github.io/langgraph/concepts/persistence/#memory-store) is just one way to store data as few-shot examples. If you want to have more developer involvement, or tie few-shots more closely to your evaluation harness, you can also use a [LangSmith Dataset](https://docs.smith.langchain.com/evaluation/how_to_guides/datasets/index_datasets_for_dynamic_few_shot_example_selection) to store your data. Then dynamic few-shot example selectors can be used out-of-the box to achieve this same goal. LangSmith will index the dataset for you and enable retrieval of few shot examples that are most relevant to the user input based upon keyword similarity ([using a BM25-like algorithm](https://docs.smith.langchain.com/how_to_guides/datasets/index_datasets_for_dynamic_few_shot_example_selection) for keyword based similarity). 
See this how-to [video](https://www.youtube.com/watch?v=37VaU7e7t5o) for example usage of dynamic few-shot example selection in LangSmith. Also, see this [blog post](https://blog.langchain.dev/few-shot-prompting-to-improve-tool-calling-performance/) showcasing few-shot prompting to improve tool calling performance and this [blog post](https://blog.langchain.dev/aligning-llm-as-a-judge-with-human-preferences/) using few-shot example to align an LLMs to human preferences.
### Procedural Memory[¶](https://langchain-ai.github.io/langgraph/concepts/memory/#procedural-memory "Permanent link")
[Procedural memory](https://en.wikipedia.org/wiki/Procedural_memory), in both humans and AI agents, involves remembering the rules used to perform tasks. In humans, procedural memory is like the internalized knowledge of how to perform tasks, such as riding a bike via basic motor skills and balance. Episodic memory, on the other hand, involves recalling specific experiences, such as the first time you successfully rode a bike without training wheels or a memorable bike ride through a scenic route. For AI agents, procedural memory is a combination of model weights, agent code, and agent's prompt that collectively determine the agent's functionality. 
In practice, it is fairly uncommon for agents to modify their model weights or rewrite their code. However, it is more common for agents to modify their own prompts. 
One effective approach to refining an agent's instructions is through ["Reflection"](https://blog.langchain.dev/reflection-agents/) or meta-prompting. This involves prompting the agent with its current instructions (e.g., the system prompt) along with recent conversations or explicit user feedback. The agent then refines its own instructions based on this input. This method is particularly useful for tasks where instructions are challenging to specify upfront, as it allows the agent to learn and adapt from its interactions.
For example, we built a [Tweet generator](https://www.youtube.com/watch?v=Vn8A3BxfplE) using external feedback and prompt re-writing to produce high-quality paper summaries for Twitter. In this case, the specific summarization prompt was difficult to specify _a priori_ , but it was fairly easy for a user to critique the generated Tweets and provide feedback on how to improve the summarization process. 
The below pseudo-code shows how you might implement this with the LangGraph memory [store](https://langchain-ai.github.io/langgraph/concepts/persistence/#memory-store), using the store to save a prompt, the `update_instructions` node to get the current prompt (as well as feedback from the conversation with the user captured in `state["messages"]`), update the prompt, and save the new prompt back to the store. Then, the `call_model` get the updated prompt from the store and uses it to generate a response.
```
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-6-1)# Node that *uses* the instructions
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-6-2)defcall_model(state: State, store: BaseStore):
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-6-3)    namespace = ("agent_instructions", )
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-6-4)    instructions = store.get(namespace, key="agent_a")[0]
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-6-5)    # Application logic
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-6-6)    prompt = prompt_template.format(instructions=instructions.value["instructions"])
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-6-7)    ...
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-6-8)
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-6-9)# Node that updates instructions
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-6-10)defupdate_instructions(state: State, store: BaseStore):
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-6-11)    namespace = ("instructions",)
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-6-12)    current_instructions = store.search(namespace)[0]
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-6-13)    # Memory logic
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-6-14)    prompt = prompt_template.format(instructions=instructions.value["instructions"], conversation=state["messages"])
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-6-15)    output = llm.invoke(prompt)
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-6-16)    new_instructions = output['new_instructions']
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-6-17)    store.put(("agent_instructions",), "agent_a", {"instructions": new_instructions})
[](https://langchain-ai.github.io/langgraph/concepts/memory/#__codelineno-6-18)    ...

```

![](https://langchain-ai.github.io/langgraph/concepts/img/memory/update-instructions.png)
## Writing memories[¶](https://langchain-ai.github.io/langgraph/concepts/memory/#writing-memories "Permanent link")
While [humans often form long-term memories during sleep](https://medicine.yale.edu/news-article/sleeps-crucial-role-in-preserving-memory/), AI agents need a different approach. When and how should agents create new memories? There are at least two primary methods for agents to write memories: "on the hot path" and "in the background".
![](https://langchain-ai.github.io/langgraph/concepts/img/memory/hot_path_vs_background.png)
### Writing memories in the hot path[¶](https://langchain-ai.github.io/langgraph/concepts/memory/#writing-memories-in-the-hot-path "Permanent link")
Creating memories during runtime offers both advantages and challenges. On the positive side, this approach allows for real-time updates, making new memories immediately available for use in subsequent interactions. It also enables transparency, as users can be notified when memories are created and stored.
However, this method also presents challenges. It may increase complexity if the agent requires a new tool to decide what to commit to memory. In addition, the process of reasoning about what to save to memory can impact agent latency. Finally, the agent must multitask between memory creation and its other responsibilities, potentially affecting the quantity and quality of memories created.
As an example, ChatGPT uses a [save_memories](https://openai.com/index/memory-and-new-controls-for-chatgpt/) tool to upsert memories as content strings, deciding whether and how to use this tool with each user message. See our [memory-agent](https://github.com/langchain-ai/memory-agent) template as an reference implementation.
### Writing memories in the background[¶](https://langchain-ai.github.io/langgraph/concepts/memory/#writing-memories-in-the-background "Permanent link")
Creating memories as a separate background task offers several advantages. It eliminates latency in the primary application, separates application logic from memory management, and allows for more focused task completion by the agent. This approach also provides flexibility in timing memory creation to avoid redundant work.
However, this method has its own challenges. Determining the frequency of memory writing becomes crucial, as infrequent updates may leave other threads without new context. Deciding when to trigger memory formation is also important. Common strategies include scheduling after a set time period (with rescheduling if new events occur), using a cron schedule, or allowing manual triggers by users or the application logic.
See our [memory-service](https://github.com/langchain-ai/memory-template) template as an reference implementation.
Was this page helpful? 
Thanks for your feedback! 
Thanks for your feedback! Please help us improve this page by adding to the discussion below. 
[ Previous  Add persistence  ](https://langchain-ai.github.io/langgraph/how-tos/persistence/) [ Next  Manage memory  ](https://langchain-ai.github.io/langgraph/how-tos/memory/)
Copyright © 2025 LangChain, Inc | [Consent Preferences](https://langchain-ai.github.io/langgraph/concepts/memory/#__consent)
Made with [ Material for MkDocs Insiders ](https://squidfunk.github.io/mkdocs-material/)
[ ](https://langchain-ai.github.io/langgraphjs/ "langchain-ai.github.io") [ ](https://github.com/langchain-ai/langgraph "github.com") [ ](https://twitter.com/LangChainAI "twitter.com")
#### Cookie consent
We use cookies to recognize your repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find what they're searching for. **Clicking "Accept" makes our documentation better. Thank you!** ❤️
  *   * 

Accept Reject
