[ Skip to content ](https://langchain-ai.github.io/langgraph/agents/streaming/#streaming)
**We are growing and hiring for multiple roles for LangChain, LangGraph and LangSmith.[ Join our team!](https://www.langchain.com/careers)**
[ ![logo](https://langchain-ai.github.io/langgraph/static/wordmark_dark.svg) ![logo](https://langchain-ai.github.io/langgraph/static/wordmark_light.svg) ](https://langchain-ai.github.io/langgraph/ "LangGraph")
LangGraph 
Streaming 
[ ](https://langchain-ai.github.io/langgraph/agents/streaming/?q= "Share")
Type to start searching
[ GitHub  ](https://github.com/langchain-ai/langgraph "Go to repository")
  * [ Guides ](https://langchain-ai.github.io/langgraph/)
  * [ Reference ](https://langchain-ai.github.io/langgraph/reference/)
  * [ Examples ](https://langchain-ai.github.io/langgraph/tutorials/rag/langgraph_agentic_rag/)
  * [ Resources ](https://langchain-ai.github.io/langgraph/concepts/faq/)


[ ![logo](https://langchain-ai.github.io/langgraph/static/wordmark_dark.svg) ![logo](https://langchain-ai.github.io/langgraph/static/wordmark_light.svg) ](https://langchain-ai.github.io/langgraph/ "LangGraph") LangGraph 
[ GitHub  ](https://github.com/langchain-ai/langgraph "Go to repository")
  * [ Guides  ](https://langchain-ai.github.io/langgraph/)
    * Get started 
      * [ Quickstart  ](https://langchain-ai.github.io/langgraph/agents/agents/)
      * [ LangGraph basics  ](https://langchain-ai.github.io/langgraph/concepts/why-langgraph/)
      * [ Deployment  ](https://langchain-ai.github.io/langgraph/tutorials/deployment/)
    * Prebuilt agents 
      * [ Overview  ](https://langchain-ai.github.io/langgraph/agents/overview/)
      * [ Running agents  ](https://langchain-ai.github.io/langgraph/agents/run_agents/)
      * Streaming  [ Streaming  ](https://langchain-ai.github.io/langgraph/agents/streaming/)
        * [ Agent progress  ](https://langchain-ai.github.io/langgraph/agents/streaming/#agent-progress)
        * [ LLM tokens  ](https://langchain-ai.github.io/langgraph/agents/streaming/#llm-tokens)
        * [ Tool updates  ](https://langchain-ai.github.io/langgraph/agents/streaming/#tool-updates)
        * [ Stream multiple modes  ](https://langchain-ai.github.io/langgraph/agents/streaming/#stream-multiple-modes)
        * [ Disable streaming  ](https://langchain-ai.github.io/langgraph/agents/streaming/#disable-streaming)
        * [ Additional resources  ](https://langchain-ai.github.io/langgraph/agents/streaming/#additional-resources)
      * [ Models  ](https://langchain-ai.github.io/langgraph/agents/models/)
      * [ Tools  ](https://langchain-ai.github.io/langgraph/agents/tools/)
      * [ MCP Integration  ](https://langchain-ai.github.io/langgraph/agents/mcp/)
      * [ Context  ](https://langchain-ai.github.io/langgraph/agents/context/)
      * [ Memory  ](https://langchain-ai.github.io/langgraph/agents/memory/)
      * [ Human-in-the-loop  ](https://langchain-ai.github.io/langgraph/agents/human-in-the-loop/)
      * [ Multi-agent  ](https://langchain-ai.github.io/langgraph/agents/multi-agent/)
      * [ Evals  ](https://langchain-ai.github.io/langgraph/agents/evals/)
      * [ Deployment  ](https://langchain-ai.github.io/langgraph/agents/deployment/)
      * [ UI  ](https://langchain-ai.github.io/langgraph/agents/ui/)
    * LangGraph framework 
      * [ Agent architectures  ](https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/)
      * [ Graphs  ](https://langchain-ai.github.io/langgraph/concepts/low_level/)
      * [ Streaming  ](https://langchain-ai.github.io/langgraph/concepts/streaming/)
      * [ Persistence  ](https://langchain-ai.github.io/langgraph/concepts/persistence/)
      * [ Memory  ](https://langchain-ai.github.io/langgraph/concepts/memory/)
      * [ Human-in-the-loop  ](https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/)
      * [ Breakpoints  ](https://langchain-ai.github.io/langgraph/concepts/breakpoints/)
      * [ Time travel  ](https://langchain-ai.github.io/langgraph/concepts/time-travel/)
      * [ Tools  ](https://langchain-ai.github.io/langgraph/concepts/tools/)
      * [ Subgraphs  ](https://langchain-ai.github.io/langgraph/concepts/subgraphs/)
      * [ Multi-agent  ](https://langchain-ai.github.io/langgraph/concepts/multi_agent/)
      * [ Functional API  ](https://langchain-ai.github.io/langgraph/concepts/functional_api/)
      * [ LangGraph's Runtime (Pregel)  ](https://langchain-ai.github.io/langgraph/concepts/pregel/)
      * [ Other  ](https://langchain-ai.github.io/langgraph/how-tos/async/)
    * LangGraph Platform 
      * [ Overview  ](https://langchain-ai.github.io/langgraph/concepts/langgraph_platform/)
      * [ Get started  ](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/)
      * [ Components  ](https://langchain-ai.github.io/langgraph/concepts/langgraph_components/)
      * [ Data management  ](https://langchain-ai.github.io/langgraph/cloud/deployment/semantic_search/)
      * [ Authentication & access control  ](https://langchain-ai.github.io/langgraph/concepts/auth/)
      * [ Assistants  ](https://langchain-ai.github.io/langgraph/concepts/assistants/)
      * [ Threads  ](https://langchain-ai.github.io/langgraph/cloud/concepts/threads/)
      * [ Runs  ](https://langchain-ai.github.io/langgraph/cloud/concepts/runs/)
      * [ Streaming  ](https://langchain-ai.github.io/langgraph/cloud/concepts/streaming/)
      * [ Human-in-the-loop  ](https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_breakpoint/)
      * [ MCP  ](https://langchain-ai.github.io/langgraph/concepts/server-mcp/)
      * [ Double-texting  ](https://langchain-ai.github.io/langgraph/concepts/double_texting/)
      * [ Webhooks  ](https://langchain-ai.github.io/langgraph/cloud/concepts/webhooks/)
      * [ Cron Jobs  ](https://langchain-ai.github.io/langgraph/cloud/concepts/cron_jobs/)
      * [ Server Customization  ](https://langchain-ai.github.io/langgraph/how-tos/http/custom_lifespan/)
      * [ Deployment  ](https://langchain-ai.github.io/langgraph/concepts/deployment_options/)
  * [ Reference  ](https://langchain-ai.github.io/langgraph/reference/)
  * [ Examples  ](https://langchain-ai.github.io/langgraph/tutorials/rag/langgraph_agentic_rag/)
  * [ Resources  ](https://langchain-ai.github.io/langgraph/concepts/faq/)


  * [ Agent progress  ](https://langchain-ai.github.io/langgraph/agents/streaming/#agent-progress)
  * [ LLM tokens  ](https://langchain-ai.github.io/langgraph/agents/streaming/#llm-tokens)
  * [ Tool updates  ](https://langchain-ai.github.io/langgraph/agents/streaming/#tool-updates)
  * [ Stream multiple modes  ](https://langchain-ai.github.io/langgraph/agents/streaming/#stream-multiple-modes)
  * [ Disable streaming  ](https://langchain-ai.github.io/langgraph/agents/streaming/#disable-streaming)
  * [ Additional resources  ](https://langchain-ai.github.io/langgraph/agents/streaming/#additional-resources)


  1. [ Guides  ](https://langchain-ai.github.io/langgraph/)
  2. [ Prebuilt agents  ](https://langchain-ai.github.io/langgraph/agents/overview/)

agent [ ](https://github.com/langchain-ai/langgraph/edit/main/docs/docs/agents/streaming.md "Edit this page")
# Streaming[¶](https://langchain-ai.github.io/langgraph/agents/streaming/#streaming "Permanent link")
Streaming is key to building responsive applications. There are a few types of data you’ll want to stream:
  1. [**Agent progress**](https://langchain-ai.github.io/langgraph/agents/streaming/#agent-progress) — get updates after each node in the agent graph is executed.
  2. [**LLM tokens**](https://langchain-ai.github.io/langgraph/agents/streaming/#llm-tokens) — stream tokens as they are generated by the language model.
  3. [**Custom updates**](https://langchain-ai.github.io/langgraph/agents/streaming/#tool-updates) — emit custom data from tools during execution (e.g., "Fetched 10/100 records")


You can stream [more than one type of data](https://langchain-ai.github.io/langgraph/agents/streaming/#stream-multiple-modes) at a time. 
![image](https://langchain-ai.github.io/langgraph/agents/assets/fast_parrot.png)
Waiting is for pigeons. 
## Agent progress[¶](https://langchain-ai.github.io/langgraph/agents/streaming/#agent-progress "Permanent link")
To stream agent progress, use the [`stream()`](https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.state.CompiledStateGraph.stream "<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">stream</span>") or [`astream()`](https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.state.CompiledStateGraph.astream "<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">astream</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-async"><code>async</code></small>
  </span>") methods with [`stream_mode="updates"`](https://langchain-ai.github.io/langgraph/how-tos/streaming/#updates). This emits an event after every agent step.
For example, if you have an agent that calls a tool once, you should see the following updates:
  * **LLM node** : AI message with tool call requests
  * **Tool node** : Tool message with execution result
  * **LLM node** : Final AI response


[Sync](https://langchain-ai.github.io/langgraph/agents/streaming/#__tabbed_1_1)[Async](https://langchain-ai.github.io/langgraph/agents/streaming/#__tabbed_1_2)
```
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-0-1)agent = create_react_agent(
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-0-2)    model="anthropic:claude-3-7-sonnet-latest",
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-0-3)    tools=[get_weather],
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-0-4))
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-0-5)for chunk in agent.stream(
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-0-6)    {"messages": [{"role": "user", "content": "what is the weather in sf"}]},
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-0-7)    stream_mode="updates"
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-0-8)):
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-0-9)    print(chunk)
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-0-10)    print("\n")

```

```
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-1-1)agent = create_react_agent(
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-1-2)    model="anthropic:claude-3-7-sonnet-latest",
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-1-3)    tools=[get_weather],
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-1-4))
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-1-5)async for chunk in agent.astream(
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-1-6)    {"messages": [{"role": "user", "content": "what is the weather in sf"}]},
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-1-7)    stream_mode="updates"
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-1-8)):
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-1-9)    print(chunk)
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-1-10)    print("\n")

```

## LLM tokens[¶](https://langchain-ai.github.io/langgraph/agents/streaming/#llm-tokens "Permanent link")
To stream tokens as they are produced by the LLM, use `stream_mode="messages"`:
[Sync](https://langchain-ai.github.io/langgraph/agents/streaming/#__tabbed_2_1)[Async](https://langchain-ai.github.io/langgraph/agents/streaming/#__tabbed_2_2)
```
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-2-1)agent = create_react_agent(
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-2-2)    model="anthropic:claude-3-7-sonnet-latest",
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-2-3)    tools=[get_weather],
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-2-4))
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-2-5)for token, metadata in agent.stream(
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-2-6)    {"messages": [{"role": "user", "content": "what is the weather in sf"}]},
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-2-7)    stream_mode="messages"
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-2-8)):
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-2-9)    print("Token", token)
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-2-10)    print("Metadata", metadata)
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-2-11)    print("\n")

```

```
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-3-1)agent = create_react_agent(
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-3-2)    model="anthropic:claude-3-7-sonnet-latest",
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-3-3)    tools=[get_weather],
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-3-4))
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-3-5)async for token, metadata in agent.astream(
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-3-6)    {"messages": [{"role": "user", "content": "what is the weather in sf"}]},
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-3-7)    stream_mode="messages"
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-3-8)):
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-3-9)    print("Token", token)
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-3-10)    print("Metadata", metadata)
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-3-11)    print("\n")

```

## Tool updates[¶](https://langchain-ai.github.io/langgraph/agents/streaming/#tool-updates "Permanent link")
To stream updates from tools as they are executed, you can use [get_stream_writer](https://langchain-ai.github.io/langgraph/reference/config/#langgraph.config.get_stream_writer "<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">get_stream_writer</span>").
[Sync](https://langchain-ai.github.io/langgraph/agents/streaming/#__tabbed_3_1)[Async](https://langchain-ai.github.io/langgraph/agents/streaming/#__tabbed_3_2)
```
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-4-1)fromlanggraph.configimport get_stream_writer
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-4-2)
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-4-3)defget_weather(city: str) -> str:
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-4-4)"""Get weather for a given city."""
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-4-5)    writer = get_stream_writer()
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-4-6)    # stream any arbitrary data
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-4-7)    writer(f"Looking up data for city: {city}")
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-4-8)    return f"It's always sunny in {city}!"
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-4-9)
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-4-10)agent = create_react_agent(
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-4-11)    model="anthropic:claude-3-7-sonnet-latest",
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-4-12)    tools=[get_weather],
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-4-13))
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-4-14)
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-4-15)for chunk in agent.stream(
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-4-16)    {"messages": [{"role": "user", "content": "what is the weather in sf"}]},
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-4-17)    stream_mode="custom"
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-4-18)):
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-4-19)    print(chunk)
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-4-20)    print("\n")

```

```
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-5-1)fromlanggraph.configimport get_stream_writer
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-5-2)
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-5-3)defget_weather(city: str) -> str:
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-5-4)"""Get weather for a given city."""
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-5-5)    writer = get_stream_writer()
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-5-6)    # stream any arbitrary data
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-5-7)    writer(f"Looking up data for city: {city}")
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-5-8)    return f"It's always sunny in {city}!"
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-5-9)
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-5-10)agent = create_react_agent(
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-5-11)    model="anthropic:claude-3-7-sonnet-latest",
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-5-12)    tools=[get_weather],
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-5-13))
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-5-14)
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-5-15)async for chunk in agent.astream(
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-5-16)    {"messages": [{"role": "user", "content": "what is the weather in sf"}]},
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-5-17)    stream_mode="custom"
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-5-18)):
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-5-19)    print(chunk)
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-5-20)    print("\n")

```

Note
If you add `get_stream_writer` inside your tool, you won't be able to invoke the tool outside of a LangGraph execution context. 
## Stream multiple modes[¶](https://langchain-ai.github.io/langgraph/agents/streaming/#stream-multiple-modes "Permanent link")
You can specify multiple streaming modes by passing stream mode as a list: `stream_mode=["updates", "messages", "custom"]`:
[Sync](https://langchain-ai.github.io/langgraph/agents/streaming/#__tabbed_4_1)[Async](https://langchain-ai.github.io/langgraph/agents/streaming/#__tabbed_4_2)
```
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-6-1)agent = create_react_agent(
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-6-2)    model="anthropic:claude-3-7-sonnet-latest",
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-6-3)    tools=[get_weather],
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-6-4))
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-6-5)
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-6-6)for stream_mode, chunk in agent.stream(
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-6-7)    {"messages": [{"role": "user", "content": "what is the weather in sf"}]},
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-6-8)    stream_mode=["updates", "messages", "custom"]
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-6-9)):
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-6-10)    print(chunk)
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-6-11)    print("\n")

```

```
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-7-1)agent = create_react_agent(
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-7-2)    model="anthropic:claude-3-7-sonnet-latest",
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-7-3)    tools=[get_weather],
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-7-4))
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-7-5)
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-7-6)async for stream_mode, chunk in agent.astream(
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-7-7)    {"messages": [{"role": "user", "content": "what is the weather in sf"}]},
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-7-8)    stream_mode=["updates", "messages", "custom"]
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-7-9)):
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-7-10)    print(chunk)
[](https://langchain-ai.github.io/langgraph/agents/streaming/#__codelineno-7-11)    print("\n")

```

## Disable streaming[¶](https://langchain-ai.github.io/langgraph/agents/streaming/#disable-streaming "Permanent link")
In some applications you might need to disable streaming of individual tokens for a given model. This is useful in [multi-agent](https://langchain-ai.github.io/langgraph/agents/multi-agent/) systems to control which agents stream their output.
See the [Models](https://langchain-ai.github.io/langgraph/agents/models/#disable-streaming) guide to learn how to disable streaming.
## Additional resources[¶](https://langchain-ai.github.io/langgraph/agents/streaming/#additional-resources "Permanent link")
  * [Streaming in LangGraph](https://langchain-ai.github.io/langgraph/how-tos/streaming)

Was this page helpful? 
Thanks for your feedback! 
Thanks for your feedback! Please help us improve this page by adding to the discussion below. 
[ Previous  Running agents  ](https://langchain-ai.github.io/langgraph/agents/run_agents/) [ Next  Models  ](https://langchain-ai.github.io/langgraph/agents/models/)
Copyright © 2025 LangChain, Inc | [Consent Preferences](https://langchain-ai.github.io/langgraph/agents/streaming/#__consent)
Made with [ Material for MkDocs Insiders ](https://squidfunk.github.io/mkdocs-material/)
[ ](https://langchain-ai.github.io/langgraphjs/ "langchain-ai.github.io") [ ](https://github.com/langchain-ai/langgraph "github.com") [ ](https://twitter.com/LangChainAI "twitter.com")
#### Cookie consent
We use cookies to recognize your repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find what they're searching for. **Clicking "Accept" makes our documentation better. Thank you!** ❤️
  *   * 

Accept Reject
