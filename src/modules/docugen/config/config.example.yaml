# DocuGen Configuration
# =====================
# DocuGen uses LangChain for universal LLM provider support.
# Supports: Ollama (local), OpenRouter, Together AI, OpenAI, and any OpenAI-compatible API.
# Copy to your working directory: cp src/modules/docugen/config/config.example.yaml config.yaml

# Step 1: LLM Connection
# ----------------------
llm:
  # API endpoint for LLM inference (OpenAI-compatible format with /v1)
  base_url: "http://localhost:11434/v1"  # Local Ollama (default)
  # base_url: "https://openrouter.ai/api/v1"     # OpenRouter
  # base_url: "https://api.together.xyz/v1"      # Together AI
  # base_url: "https://api.openai.com/v1"        # OpenAI
  # base_url: "http://localhost:1234/v1"         # LM Studio

  # API key environment variable (leave null for local Ollama)
  # Set the actual key in .env file: OPENROUTER_API_KEY=your-key-here
  api_key_env: null  # e.g., "OPENROUTER_API_KEY", "OPENAI_API_KEY", "TOGETHER_API_KEY"

  timeout: 300  # Request timeout (seconds)

# Step 2: Model Selection
# -----------------------
models:
  default: "codellama:13b"              # General purpose
  summarizer: "codellama:7b"            # Layer 1 - Fast, high-level summaries
  detailing: "codellama:13b"            # Layer 2 - Detailed documentation (quality critical)
  relationship_mapper: "codellama:7b"   # Layer 3 - Dependency analysis
  validation: null                      # Validation model (defaults to detailing if null)

# Step 3: Quality Validation
# ---------------------------
validation:
  max_iterations: 3                     # Refinement attempts before manual review (1-10)
  min_summary_length: 50                # Minimum summary length (characters)
  require_all_public_methods: true      # Enforce complete method documentation

# Step 4: Output Settings
# -----------------------
output:
  base_path: "./docs_output"            # Documentation output directory
  format: "markdown"                    # Output format
  include_metadata: true                # Include generation timestamps and validation status

# Step 5: Processing Options
# ---------------------------
processing:
  parallel_files: 4                     # Concurrent file processing (1-16, adjust for hardware)
  enable_incremental: true              # Only re-process changed files (not yet implemented)
  supported_languages:
    - "csharp"

# Notes:
# - For local Ollama: Model names must exist (check with: ollama list)
# - For OpenRouter/OpenAI: Use provider/model format (e.g., "anthropic/claude-3-5-sonnet", "gpt-4")
# - API keys should be stored in .env file and referenced via api_key_env
# - Memory usage scales with parallel_files and model size
# - For large codebases (5000+ files), reduce parallel_files to 2-4
# - Use verbose mode for debugging: docugen document -v
# - Test connection: docugen test-connection
